
run_name: torch-training-iso

wandb_entity: null
wandb_project: cwic

teacher_model: unsloth/Llama-3.2-1B-Instruct

batch_size: 8

checkpoint_interval: 16000

start_compute_reduction: 1.0
end_compute_reduction: 6.0
compute_reduction_steps: 160000

model:

  stripe_size: 1024
  head_stripe_size: 8192

  head_limit: 100.0

  threshold_lr_scale: 10.0
  threshold_init: 0.0
  threshold_minimum: 0.001

  bandwidth: 0.1

  stats_beta: 0.9993720513
  median_iters: 3


dataset:

  path: crystal-ai/chat-compilation-benchmark-5x-Llama-3.2-Instruct-Shuffled

  split: train
  streaming: true


optimizer:

  lr: 0.000003061862178
  weight_decay: 0.016

  betas: [0.9934366016, 0.9967993023]


lr_scheduler:

  name: linear

  num_warmup_steps: 100
  num_training_steps: 10000
